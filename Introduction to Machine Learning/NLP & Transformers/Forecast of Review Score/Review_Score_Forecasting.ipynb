{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import of necessary libraries :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srgh97xSpY93",
        "outputId": "aeaa1b95-7721-4046-80ee-496190083f26"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "  0%|          | 0/391 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "100%|██████████| 391/391 [02:10<00:00,  2.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5, Loss: 7.0269\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [02:10<00:00,  3.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/5, Loss: 1.2878\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [02:11<00:00,  2.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/5, Loss: 0.5940\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [02:10<00:00,  3.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/5, Loss: 0.3884\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [02:10<00:00,  3.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/5, Loss: 0.2878\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:44<00:00,  8.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss (MSE): 0.1601\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [00:04<00:00,  7.56it/s]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data preprocessing (Tokenizer, Loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, data_frame, tokenizer, max_length, is_test=False):\n",
        "        self.data = data_frame\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.is_test = is_test\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        title = str(self.data.iloc[index]['title'])\n",
        "        sentence = str(self.data.iloc[index]['sentence'])\n",
        "        inputs = self.tokenizer(title + \" \" + sentence, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "        item = {key: value.squeeze(0) for key, value in inputs.items()}\n",
        "        if not self.is_test:\n",
        "            item['score'] = torch.tensor(float(self.data.iloc[index]['score']), dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test_no_score.csv\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "max_length = 128\n",
        "\n",
        "train_dataset = ReviewDataset(train_df, tokenizer, max_length)\n",
        "test_dataset = ReviewDataset(test_df, tokenizer, max_length, is_test=True)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True, num_workers=16, pin_memory=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False, num_workers=16, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DistilBERT Transformer and MLP Regression Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model Architecture\n",
        "class MyModule(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModule, self).__init__()\n",
        "        self.distilbert = AutoModel.from_pretrained('distilbert-base-uncased')\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc1 = nn.Linear(768, 256)\n",
        "        self.fc2 = nn.Linear(256, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]  # Take the [CLS] token\n",
        "        x = self.dropout(pooled_output)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = nn.functional.relu(self.fc2(x))\n",
        "        output = self.fc3(x)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Training (Optimiser and criterion setup etc..)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MyModule().to(DEVICE)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Training Loop\n",
        "NUM_EPOCHS = 5\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for batch in tqdm(train_loader, total=len(train_loader)):\n",
        "        input_ids = batch['input_ids'].to(DEVICE)\n",
        "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
        "        targets = batch['score'].unsqueeze(1).to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    epoch_loss /= len(train_loader)\n",
        "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {epoch_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, total=len(loader)):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            targets = batch['score'].unsqueeze(1).to(device)\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            loss = criterion(outputs, targets)\n",
        "            epoch_loss += loss.item()\n",
        "    return epoch_loss / len(loader)\n",
        "\n",
        "train_loss = evaluate(model, train_loader, criterion, DEVICE)\n",
        "print(f'Training Loss (MSE): {train_loss:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prediction of reviews' scores "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prediction\n",
        "def predict(model, loader, device):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, total=len(loader)):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            predictions.extend(outputs.cpu().squeeze().tolist())\n",
        "    return predictions\n",
        "\n",
        "test_predictions = predict(model, test_loader, DEVICE)\n",
        "\n",
        "# Save Predictions to TXT File\n",
        "with open(\"results.txt\", \"w\") as file:\n",
        "    for prediction in test_predictions:\n",
        "        file.write(f\"{prediction:.2f}\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
